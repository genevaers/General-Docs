# How many address spaces does SAFR use? {#SARFaq3AddressSpaces .reference}

There are several steps in the SAFR batch process, but all the "magic" happens in one address space, and that's part of the power of the product and the reason why z/OS is an excellent platform for solving large Business Intelligence \(BI\) problems.

All tables fall into one of two classes: source tables \(data you for your lookups to access\) and lookup tables \(data provided by your lookups\). Source tables may be very large sequential data stores, such as the last ten years of transaction history stored on tape. Lookup tables, such as customer tables, are usually more reasonably sized and can fit completely in memory \(especially after we've discarded all the columns which are not be needed in the current batch run\). SAFR ran for many years at Intel Corporation with no need for more than 10 GB of lookup data in memory. SAFR never needed to hold more than 20 GB in memory. If the customer's lookup data is too voluminous for a typical SAFR process to run on their machine, SAFR can use other methods employing match/merge techniques to solve the business problem.

SAFR pre-scans all the lookup data, stores the relevant data in memory, and builds a binary search tree for fast retrieval. We do not know of any other product that does this. It's economical for SAFR to do this because it's optimizing for the query workload and the initial costs are spread out over many queries. Once the lookup data is in memory, SAFR generates highly tuned machine code for each query on the fly and spawn a separate thread \(MVS subtask\) for each chunk of source data \(sequential file, DB2 table partition, etc.\). SAFR has sometimes executed 500 sub-tasks in one address space.

Other BI tools try to solve large query problems by splitting up the source data and having separate processors \("massively parallel processing"\) or separate address spaces each work on their own piece of the problem. The disadvantage to this approach is that the separate processes don't have quick access to the lookup tables, and SAFR has learned over many years of solving enterprise-class reporting problems that it's the CPU time required for a join that really kills performance. Because SAFR lookup data is pre-indexed and easily accessible in the same address space as the data reader tasks, SAFR can do table lookups in typically 7 machine language instructions. \(SAFR has been clocked at executing up to 2 million table lookups per CPU second on a 2094 machine.\) And because SAFR satisfies multiple queries simultaneously, SAFR can leverage the cost of an expensive join over many queries. DB2 is a wonderful tool, but it's "solving the problem for the general case" because it never knows what query is coming next. SAFR "solves the problem for the specific case" of the current query workload, whether it be 10, 100, or 1000 queries.

System z is perfectly suited for this type of application because of its "shared everything" architecture and high I/O bandwidth. Multiple processors, multiple I/O channels, shared disk, and large amounts of shared memory can all be brought to bear on a specific query workload in a single address space, minimizing CPU time and elapsed time. Alternative strategies fail because of excessive cross-address space communication. And, because z/OS excels at mixed workloads, it is not necessary to have a dedicated machine to execute large reporting applications \(as often occurs in UNIX environments\).

**Parent topic:**[FAQ](../html/SARFaq0.md)

